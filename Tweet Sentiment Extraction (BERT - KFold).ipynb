{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import transformers\n",
    "import tokenizers\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'data_dir': '/data/ai_challenge/tweet_sentiment_extraction/',\n",
    "    'train_file': 'train.csv',\n",
    "    'test_file': 'test.csv',\n",
    "    'save_model_dir': 'trained_model',\n",
    "    \n",
    "    'model_name': 'bert-base-uncased',\n",
    "    'do_eval': False,\n",
    "    'gradient_accumulation_steps': 1,\n",
    "    'max_seq_length': 128,\n",
    "    'batch_size': 8,\n",
    "    'n_epoch': 3,\n",
    "    'weight_decay': 1e-7,\n",
    "    'adam_epsilon': 1e-8,\n",
    "    'warmup_steps': 0,\n",
    "    'n_splits': 5,\n",
    "    'learning_rate': 1e-5,\n",
    "    'seed': 1234,\n",
    "}\n",
    "\n",
    "# class config:\n",
    "#     DATA_DIR = '../input/tweet-sentiment-extraction'\n",
    "#     BERT_PATH = '../input/bert-base-uncased'\n",
    "#     OUTPUT_DIR = '/kaggle/working'\n",
    "#     TRAIN_FILE = 'train.csv'\n",
    "#     TEST_FILE = 'test.csv'\n",
    "#     SAVE_MODEL_DIR = ''\n",
    "#     MAX_LEN = 128\n",
    "#     TRAIN_BATCH_SIZE = 32\n",
    "#     VALID_BATCH_SIZE = 32\n",
    "#     EPOCHS = 3\n",
    "#     N_SPLITS = 5\n",
    "#     SEED = 1234\n",
    "#     TOKENIZER = tokenizers.BertWordPieceTokenizer(\n",
    "#         f\"{BERT_PATH}/vocab.txt\", \n",
    "#         lowercase=True\n",
    "#     )\n",
    "\n",
    "class config:\n",
    "    DATA_DIR = '/data/ai_challenge/tweet_sentiment_extraction'\n",
    "    BERT_PATH = '/data/ai_challenge/tweet_sentiment_extraction/bert-base-uncased'\n",
    "    OUTPUT_DIR = '/data/ai_challenge/tweet_sentiment_extraction'\n",
    "    TRAIN_FILE = 'train.csv'\n",
    "    TEST_FILE = 'test.csv'\n",
    "    SAVE_MODEL_DIR = 'trained_model'\n",
    "    MAX_LEN = 128\n",
    "    TRAIN_BATCH_SIZE = 8\n",
    "    VALID_BATCH_SIZE = 8\n",
    "    LOGGING_STEPS = 100\n",
    "    LEARNING_RATE = 3e-5\n",
    "    WEIGHT_DECAY = 1e-3\n",
    "    EPOCHS = 3\n",
    "    N_SPLITS = 5\n",
    "    PATIENCE = 2\n",
    "    SEED = 1234\n",
    "    DEVICE = torch.device('cuda')\n",
    "    TOKENIZER = tokenizers.BertWordPieceTokenizer(\n",
    "        f\"{BERT_PATH}/vocab.txt\", \n",
    "        lowercase=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "seed_everything(config.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, mode=\"max\", delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "        if self.mode == \"min\":\n",
    "            self.val_score = np.Inf\n",
    "        else:\n",
    "            self.val_score = -np.Inf\n",
    "\n",
    "    def __call__(self, epoch_score, model, model_path):\n",
    "\n",
    "        if self.mode == \"min\":\n",
    "            score = -1.0 * epoch_score\n",
    "        else:\n",
    "            score = np.copy(epoch_score)\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(epoch_score, model, model_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, epoch_score, model, model_path):\n",
    "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n",
    "            print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score, epoch_score))\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        self.val_score = epoch_score\n",
    "\n",
    "\n",
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(tweet, selected_text, sentiment, tokenizer, max_len):\n",
    "    len_st = len(selected_text)\n",
    "    idx0 = None\n",
    "    idx1 = None\n",
    "    \n",
    "    # Test again\n",
    "    for ind in (i for i, e in enumerate(tweet) if e == selected_text[0]):\n",
    "        if tweet[ind: ind+len_st] == selected_text:\n",
    "            idx0 = ind\n",
    "            idx1 = ind + len_st - 1\n",
    "            break\n",
    "            \n",
    "    char_targets = [0] * len(tweet)\n",
    "    if idx0 != None and idx1 != None:\n",
    "        for ct in range(idx0, idx1 + 1):\n",
    "            char_targets[ct] = 1\n",
    "            \n",
    "    tok_tweet = tokenizer.encode(tweet)\n",
    "    input_ids_orig = tok_tweet.ids[1: -1]\n",
    "    tweet_offsets = tok_tweet.offsets[1: -1]\n",
    "    \n",
    "    target_idx = [] # offset of token in sentence\n",
    "    for j, (offset1, offset2) in enumerate(tweet_offsets):\n",
    "        if sum(char_targets[offset1: offset2]) > 0:\n",
    "            target_idx.append(j)\n",
    "            \n",
    "    targets_start = target_idx[0]\n",
    "    targets_end = target_idx[-1]\n",
    "    \n",
    "    sentiment_id = {\n",
    "        'positive': 3893,\n",
    "        'negative': 4997,\n",
    "        'neutral': 8699\n",
    "    }\n",
    "    \n",
    "    input_ids = [101] + [sentiment_id[sentiment]] + [102] + input_ids_orig + [102]\n",
    "    token_type_ids = [0, 0, 0] + [1] * (len(input_ids_orig) + 1)\n",
    "    mask = [1] * len(token_type_ids)\n",
    "    tweet_offsets = [(0, 0)] * 3 + tweet_offsets + [(0, 0)]\n",
    "    targets_start += 3\n",
    "    targets_end += 3\n",
    "    \n",
    "    padding_length = max_len - len(input_ids)\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
    "        tweet_offsets = tweet_offsets + ([(0, 0)] * padding_length)\n",
    "        \n",
    "    return {\n",
    "        'ids': input_ids,\n",
    "        'mask': mask,\n",
    "        'token_type_ids': token_type_ids,\n",
    "        'targets_start': targets_start,\n",
    "        'targets_end': targets_end,\n",
    "        'orig_tweet': tweet,\n",
    "        'orig_selected': selected_text,\n",
    "        'sentiment': sentiment,\n",
    "        'offsets': tweet_offsets\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset :\n",
    "    def __init__(self, tweet, sentiment, selected_text):\n",
    "        self.tweet = tweet\n",
    "        self.sentiment = sentiment\n",
    "        self.selected_text = selected_text\n",
    "        self.tokenizer = config.TOKENIZER\n",
    "        self.max_len = config.MAX_LEN\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tweet)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        data = process_data(\n",
    "            self.tweet[item],\n",
    "            self.selected_text[item],\n",
    "            self.sentiment[item],\n",
    "            self.tokenizer,\n",
    "            self.max_len\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(data['ids'], dtype=torch.long),\n",
    "            'mask': torch.tensor(data['mask'], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n",
    "            'targets_start': torch.tensor(data[\"targets_start\"], dtype=torch.long),\n",
    "            'targets_end': torch.tensor(data[\"targets_end\"], dtype=torch.long),\n",
    "            'orig_tweet': data[\"orig_tweet\"],\n",
    "            'orig_selected': data[\"orig_selected\"],\n",
    "            'sentiment': data[\"sentiment\"],\n",
    "            'offsets': torch.tensor(data[\"offsets\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetModel(transformers.BertPreTrainedModel):\n",
    "    def __init__(self, conf):\n",
    "        super(TweetModel, self).__init__(conf)\n",
    "        self.bert = transformers.BertModel.from_pretrained(config.BERT_PATH, config=conf)\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.l0 = nn.Linear(768 * 2, 2)\n",
    "        nn.init.normal_(self.l0.weight, std=0.02)\n",
    "        \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, _, out = self.bert(\n",
    "            ids, \n",
    "            attention_mask = mask,\n",
    "            token_type_ids = token_type_ids\n",
    "        )\n",
    "        \n",
    "        out = torch.cat((out[-1], out[-2]), dim=-1)\n",
    "        out = self.drop_out(out)\n",
    "        logits = self.l0(out)\n",
    "\n",
    "        start_logits, end_logits = logits.split(1, dim=-1)\n",
    "\n",
    "        start_logits = start_logits.squeeze(-1)\n",
    "        end_logits = end_logits.squeeze(-1)\n",
    "\n",
    "        return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(start_logits, end_logits, start_positions, end_positions):\n",
    "    loss_fct = nn.CrossEntropyLoss()\n",
    "    start_loss = loss_fct(start_logits, start_positions)\n",
    "    end_loss = loss_fct(end_logits, end_positions)\n",
    "    total_loss = start_loss + end_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Valid Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer, scheduler=None):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    jaccards = AverageMeter()\n",
    "    \n",
    "    tk0 = tqdm(data_loader, total=len(data_loader), desc='Train')\n",
    "    for bi, d in enumerate(tk0):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        sentiment = d[\"sentiment\"]\n",
    "        orig_selected = d[\"orig_selected\"]\n",
    "        orig_tweet = d[\"orig_tweet\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        offsets = d[\"offsets\"]\n",
    "\n",
    "        ids = ids.to(config.DEVICE, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(config.DEVICE, dtype=torch.long)\n",
    "        mask = mask.to(config.DEVICE, dtype=torch.long)\n",
    "        targets_start = targets_start.to(config.DEVICE, dtype=torch.long)\n",
    "        targets_end = targets_end.to(config.DEVICE, dtype=torch.long)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        outputs_start, outputs_end = model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
    "        \n",
    "        loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "        jaccard_scores = []\n",
    "        \n",
    "        for px, tweet in enumerate(orig_tweet):\n",
    "            selected_tweet = orig_selected[px]\n",
    "            tweet_sentiment = sentiment[px]\n",
    "            jaccard_score, _ = calculate_jaccard_score(\n",
    "                original_tweet=tweet,\n",
    "                target_string=selected_tweet,\n",
    "                sentiment_val=tweet_sentiment,\n",
    "                idx_start=np.argmax(outputs_start[px, :]),\n",
    "                idx_end=np.argmax(outputs_end[px, :]),\n",
    "                offsets=offsets[px]\n",
    "            )\n",
    "            jaccard_scores.append(jaccard_score)\n",
    "        \n",
    "        jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
    "        losses.update(loss.item(), ids.size(0))\n",
    "        if bi >= config.LOGGING_STEPS and bi % config.LOGGING_STEPS == 0:\n",
    "            print(f\"Loss: {losses.avg} - Jaccard: {jaccards.avg}\")\n",
    "            losses.reset()\n",
    "            jaccards.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_jaccard_score(original_tweet, target_string, sentiment_val, idx_start, idx_end, offsets):\n",
    "    if idx_end < idx_start:\n",
    "        idx_end = idx_start\n",
    "        \n",
    "    filtered_output  = \"\"\n",
    "    for ix in range(idx_start, idx_end + 1):\n",
    "        filtered_output += original_tweet[offsets[ix][0]: offsets[ix][1]]\n",
    "        if (ix+1) < len(offsets) and offsets[ix][1] < offsets[ix+1][0]:\n",
    "            filtered_output += \" \"\n",
    "            \n",
    "    if sentiment_val == 'neutral' or len(original_tweet.split()) < 2:\n",
    "        filtered_output = original_tweet\n",
    "        \n",
    "    jac = jaccard(target_string.strip(), filtered_output.strip())\n",
    "    \n",
    "    return jac, filtered_output\n",
    "\n",
    "def eval_fn(data_loader, model):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    jaccards = AverageMeter()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        tk0 = tqdm(data_loader, total=len(data_loader), desc='Valid')\n",
    "        for bi, d in enumerate(tk0):\n",
    "            ids = d[\"ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            sentiment = d[\"sentiment\"]\n",
    "            orig_selected = d[\"orig_selected\"]\n",
    "            orig_tweet = d[\"orig_tweet\"]\n",
    "            targets_start = d[\"targets_start\"]\n",
    "            targets_end = d[\"targets_end\"]\n",
    "            offsets = d[\"offsets\"].numpy()\n",
    "\n",
    "            ids = ids.to(config.DEVICE, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(config.DEVICE, dtype=torch.long)\n",
    "            mask = mask.to(config.DEVICE, dtype=torch.long)\n",
    "            targets_start = targets_start.to(config.DEVICE, dtype=torch.long)\n",
    "            targets_end = targets_end.to(config.DEVICE, dtype=torch.long)\n",
    "\n",
    "            outputs_start, outputs_end = model(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            loss = loss_fn(outputs_start, outputs_end, targets_start, targets_end)\n",
    "            outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "            outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "            jaccard_scores = []\n",
    "            for px, tweet in enumerate(orig_tweet):\n",
    "                selected_tweet = orig_selected[px]\n",
    "                tweet_sentiment = sentiment[px]\n",
    "                jaccard_score, _ = calculate_jaccard_score(\n",
    "                    original_tweet=tweet,\n",
    "                    target_string=selected_tweet,\n",
    "                    sentiment_val=tweet_sentiment,\n",
    "                    idx_start=np.argmax(outputs_start[px, :]),\n",
    "                    idx_end=np.argmax(outputs_end[px, :]),\n",
    "                    offsets=offsets[px]\n",
    "                )\n",
    "                jaccard_scores.append(jaccard_score)\n",
    "\n",
    "            jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
    "            losses.update(loss.item(), ids.size(0))\n",
    "            tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)\n",
    "    \n",
    "    print(f\"Validation Jaccard = {jaccards.avg}\")\n",
    "    return jaccards.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fold, train_data_loader, valid_data_loader, train_size, model_config):\n",
    "    model = TweetModel(conf=model_config)\n",
    "    model.to(config.DEVICE)\n",
    "    \n",
    "    num_train_steps = int(train_size / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': config.WEIGHT_DECAY},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_parameters, lr=config.LEARNING_RATE)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=0, \n",
    "        num_training_steps=num_train_steps\n",
    "    )\n",
    "    \n",
    "    es = EarlyStopping(patience=config.PATIENCE, mode=\"max\")\n",
    "    \n",
    "    for epoch in range(config.EPOCHS):\n",
    "        train_fn(train_data_loader, model, optimizer, scheduler=scheduler)\n",
    "        jaccard = eval_fn(valid_data_loader, model)\n",
    "        es(jaccard, model, model_path=f\"{config.OUTPUT_DIR}/{config.SAVE_MODEL_DIR}/model_fold_{fold}.bin\")\n",
    "        if es.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0425 23:21:03.642301 139864187406080 configuration_utils.py:149] loading configuration file /data/ai_challenge/tweet_sentiment_extraction/bert-base-uncased/config.json\n",
      "I0425 23:21:03.643000 139864187406080 configuration_utils.py:169] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0425 23:21:03.646480 139864187406080 modeling_utils.py:384] loading weights file /data/ai_challenge/tweet_sentiment_extraction/bert-base-uncased/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Fold 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4cf75350b84e0183a17c32004303c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2748), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.006890003043826 - Jaccard: 0.5641843551036889\n",
      "Loss: 2.3982258260250093 - Jaccard: 0.6278097417701818\n",
      "Loss: 2.1957616502046586 - Jaccard: 0.6605873786543285\n",
      "Loss: 2.2117417457699777 - Jaccard: 0.6587832252461537\n",
      "Loss: 2.0294745269417764 - Jaccard: 0.6834536842008329\n",
      "Loss: 2.000752937793732 - Jaccard: 0.6589861732157594\n",
      "Loss: 2.0507117620110513 - Jaccard: 0.6529942369698438\n",
      "Loss: 2.023613204956055 - Jaccard: 0.6436526877577187\n",
      "Loss: 1.9709315341711044 - Jaccard: 0.6747795378235841\n",
      "Loss: 2.0475505888462067 - Jaccard: 0.6696222275010871\n",
      "Loss: 2.0431724429130553 - Jaccard: 0.650858327888883\n",
      "Loss: 1.9772656041383743 - Jaccard: 0.6585664789287548\n",
      "Loss: 2.0552616330981253 - Jaccard: 0.6609851099666662\n",
      "Loss: 1.8740272343158721 - Jaccard: 0.6770454389736977\n",
      "Loss: 1.765090399980545 - Jaccard: 0.6827987630838354\n",
      "Loss: 1.9156112080812455 - Jaccard: 0.683015192905799\n",
      "Loss: 1.91412092640996 - Jaccard: 0.6775231139694191\n",
      "Loss: 1.8191272270679475 - Jaccard: 0.6838461505192979\n",
      "Loss: 1.7774360516667367 - Jaccard: 0.6845139834199614\n",
      "Loss: 1.753701505959034 - Jaccard: 0.6843024141909676\n",
      "Loss: 1.8617056095600129 - Jaccard: 0.6917978678875292\n",
      "Loss: 1.6457648023962974 - Jaccard: 0.7180861915478107\n",
      "Loss: 1.8357903516292573 - Jaccard: 0.6682243213543292\n",
      "Loss: 1.8755778580904008 - Jaccard: 0.684785469422863\n",
      "Loss: 1.7829305881261825 - Jaccard: 0.7098836999018054\n",
      "Loss: 1.861888365149498 - Jaccard: 0.6792722212689415\n",
      "Loss: 1.8204134929180145 - Jaccard: 0.678726570107608\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1552318eabe48488ae841874cd08052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=688), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.6924205063985204\n",
      "Validation score improved (-inf --> 0.6924205063985204). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086fd15d241c4591869043e79d86e3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2748), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6106412092057785 - Jaccard: 0.7209827439982722\n",
      "Loss: 1.5524682834744454 - Jaccard: 0.7119186405242446\n",
      "Loss: 1.438403276503086 - Jaccard: 0.7309713882697799\n",
      "Loss: 1.451978203356266 - Jaccard: 0.7249674359932761\n",
      "Loss: 1.552498097717762 - Jaccard: 0.7198944857517\n",
      "Loss: 1.4662634551525116 - Jaccard: 0.730182983043756\n",
      "Loss: 1.4619652596116066 - Jaccard: 0.7281056459082029\n",
      "Loss: 1.3672282102704048 - Jaccard: 0.7402388916354566\n",
      "Loss: 1.486831073462963 - Jaccard: 0.7379813036483414\n",
      "Loss: 1.4282226225733756 - Jaccard: 0.7444991814764838\n",
      "Loss: 1.4905841171741485 - Jaccard: 0.7297055939130245\n",
      "Loss: 1.520411153435707 - Jaccard: 0.7173051083202706\n",
      "Loss: 1.4854453736543656 - Jaccard: 0.7275581279192997\n",
      "Loss: 1.5596366119384766 - Jaccard: 0.7230809959096764\n",
      "Loss: 1.399848034977913 - Jaccard: 0.7368017627452451\n",
      "Loss: 1.5916595500707627 - Jaccard: 0.7146032801694497\n",
      "Loss: 1.5352915725111962 - Jaccard: 0.7212640226350238\n",
      "Loss: 1.4115150326490402 - Jaccard: 0.7497325916256868\n",
      "Loss: 1.5370115250349046 - Jaccard: 0.7349139898513894\n",
      "Loss: 1.4228201073408127 - Jaccard: 0.7426078641325753\n",
      "Loss: 1.4901558363437652 - Jaccard: 0.7347679813521532\n",
      "Loss: 1.4711302450299264 - Jaccard: 0.7438555494493074\n",
      "Loss: 1.5600390127301216 - Jaccard: 0.7144826432433908\n",
      "Loss: 1.5554282730817794 - Jaccard: 0.7154565545749045\n",
      "Loss: 1.5508367067575455 - Jaccard: 0.7159886348813967\n",
      "Loss: 1.5858826270699502 - Jaccard: 0.6912360669006365\n",
      "Loss: 1.5163040214776993 - Jaccard: 0.7162917495243032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510c966118874d1980365b652f4a1232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=688), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.6996168272292659\n",
      "Validation score improved (0.6924205063985204 --> 0.6996168272292659). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb3fb811a26454f9a95087b4974661f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2748), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0487954619497355 - Jaccard: 0.7988509902848977\n",
      "Loss: 1.1027327516674996 - Jaccard: 0.7969612875441274\n",
      "Loss: 1.0156351475417613 - Jaccard: 0.7922009015621775\n",
      "Loss: 1.1125477030873299 - Jaccard: 0.7861659920748478\n",
      "Loss: 1.1701165410876273 - Jaccard: 0.7886576847795778\n",
      "Loss: 0.9759951317310334 - Jaccard: 0.8085783529152663\n",
      "Loss: 1.2069919748604299 - Jaccard: 0.762329272854133\n",
      "Loss: 1.0497337731719016 - Jaccard: 0.7861751067027604\n",
      "Loss: 1.060850309729576 - Jaccard: 0.8108737340260563\n",
      "Loss: 1.07986856803298 - Jaccard: 0.7853398800230219\n",
      "Loss: 1.0388491544127465 - Jaccard: 0.8018827597319668\n",
      "Loss: 1.080313804447651 - Jaccard: 0.7962434426565831\n",
      "Loss: 1.1397690007090568 - Jaccard: 0.7702624389548413\n",
      "Loss: 1.0449483475089074 - Jaccard: 0.8028653378304498\n",
      "Loss: 1.1259951019287109 - Jaccard: 0.7773704552083585\n",
      "Loss: 1.1304967713356018 - Jaccard: 0.7723870945543142\n",
      "Loss: 1.1517181631922722 - Jaccard: 0.7765852713713275\n",
      "Loss: 1.109026340842247 - Jaccard: 0.7808896450578148\n",
      "Loss: 1.0770033624768258 - Jaccard: 0.7909033917470946\n",
      "Loss: 1.053327139019966 - Jaccard: 0.7793405418730903\n",
      "Loss: 1.201389707326889 - Jaccard: 0.7644405149357846\n",
      "Loss: 1.0729101058095694 - Jaccard: 0.7838342862960502\n",
      "Loss: 1.0125224754214286 - Jaccard: 0.7972944927615803\n",
      "Loss: 1.1591342353820802 - Jaccard: 0.7677387436015344\n",
      "Loss: 1.075653255134821 - Jaccard: 0.7872215892370484\n",
      "Loss: 0.9800043946504593 - Jaccard: 0.8131768378668472\n",
      "Loss: 1.0667034351825715 - Jaccard: 0.7934262012657615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f636bc6b3546b6b34ef0c590f4f1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=688), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.6989393613660492\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9db55b143c47aba0407e43930d5f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2748), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6883146016314479 - Jaccard: 0.8459134290737462\n",
      "Loss: 0.6483116732537746 - Jaccard: 0.8539020519272233\n",
      "Loss: 0.6224688391387463 - Jaccard: 0.8648387561284548\n",
      "Loss: 0.6385715100169181 - Jaccard: 0.8676617607935543\n",
      "Loss: 0.7442042492330074 - Jaccard: 0.8402445831181015\n",
      "Loss: 0.7288773839175701 - Jaccard: 0.8569386740166776\n",
      "Loss: 0.6815322598814965 - Jaccard: 0.8278711281249901\n",
      "Loss: 0.7766256174445152 - Jaccard: 0.8336424901487404\n",
      "Loss: 0.6366028183698654 - Jaccard: 0.8706729201770226\n",
      "Loss: 0.6898996062576771 - Jaccard: 0.8536926574198397\n",
      "Loss: 0.704504166096449 - Jaccard: 0.851559953214262\n",
      "Loss: 0.6701661312580108 - Jaccard: 0.8410364529424705\n",
      "Loss: 0.7222430995106697 - Jaccard: 0.8353002373741443\n",
      "Loss: 0.6501882456243038 - Jaccard: 0.8636141015954286\n",
      "Loss: 0.7024543158710003 - Jaccard: 0.8513693450127131\n",
      "Loss: 0.7169994602352381 - Jaccard: 0.8621633893000481\n",
      "Loss: 0.6804216329753399 - Jaccard: 0.8496835735883785\n",
      "Loss: 0.750208730250597 - Jaccard: 0.8358955489487778\n",
      "Loss: 0.6808011692762375 - Jaccard: 0.8421523474071367\n",
      "Loss: 0.6518179750442505 - Jaccard: 0.8603450691566255\n",
      "Loss: 0.6864548327028751 - Jaccard: 0.8376219819245942\n",
      "Loss: 0.6612639137357473 - Jaccard: 0.8510601880784749\n",
      "Loss: 0.6355977611243725 - Jaccard: 0.8534935289158295\n",
      "Loss: 0.6324855831637979 - Jaccard: 0.8693594486569648\n",
      "Loss: 0.6831888914108276 - Jaccard: 0.8505906981490956\n",
      "Loss: 0.707743856832385 - Jaccard: 0.8537541851351059\n",
      "Loss: 0.6943989618122578 - Jaccard: 0.8430946057774338\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50de67423e83475a80a94b52fe919f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=688), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0426 00:23:55.935435 139864187406080 modeling_utils.py:384] loading weights file /data/ai_challenge/tweet_sentiment_extraction/bert-base-uncased/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.6903527387172474\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Early stopping\n",
      "Train Fold 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4712a72a2bdb47cc9f05a806c59db6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2748), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.9250927809441443 - Jaccard: 0.5648147640048645\n",
      "Loss: 2.2488807797431947 - Jaccard: 0.6365967051317013\n",
      "Loss: 2.1950877195596696 - Jaccard: 0.6413079554057249\n",
      "Loss: 2.1762791341543197 - Jaccard: 0.6547034876981824\n",
      "Loss: 2.1291297167539596 - Jaccard: 0.6579244433677441\n",
      "Loss: 1.9569959825277328 - Jaccard: 0.6673747601274098\n",
      "Loss: 2.0354069769382477 - Jaccard: 0.6631110626581954\n",
      "Loss: 1.9677068692445756 - Jaccard: 0.6759339485578733\n",
      "Loss: 1.8674519318342209 - Jaccard: 0.679766372172262\n",
      "Loss: 1.9253307110071183 - Jaccard: 0.6935863341782468\n",
      "Loss: 1.8641150999069214 - Jaccard: 0.6867079773952899\n",
      "Loss: 1.7604672312736511 - Jaccard: 0.685902734973668\n",
      "Loss: 1.8455585324764252 - Jaccard: 0.6750558153002418\n",
      "Loss: 1.8171142828464508 - Jaccard: 0.6784543575569466\n",
      "Loss: 1.9242721816897392 - Jaccard: 0.6794612118954185\n",
      "Loss: 1.7227347409725189 - Jaccard: 0.7114230449603977\n",
      "Loss: 1.906080068051815 - Jaccard: 0.6706429195369963\n",
      "Loss: 1.7305699768662453 - Jaccard: 0.6994914250083386\n",
      "Loss: 1.7288948985934258 - Jaccard: 0.6992228275225504\n",
      "Loss: 1.826353333592415 - Jaccard: 0.6856531107824533\n",
      "Loss: 1.8157851395010949 - Jaccard: 0.6887466229268665\n",
      "Loss: 1.7533026933670044 - Jaccard: 0.7033941475650458\n",
      "Loss: 1.867195537686348 - Jaccard: 0.6871329901330564\n",
      "Loss: 1.8907083600759507 - Jaccard: 0.6853201746771889\n",
      "Loss: 1.8416290187835693 - Jaccard: 0.6844333246145241\n",
      "Loss: 1.7487821027636528 - Jaccard: 0.7026949099190829\n",
      "Loss: 1.7534769970178603 - Jaccard: 0.7049069765054108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab18b71d57948588b6c1070d893be6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=688), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.7027429484610169\n",
      "Validation score improved (-inf --> 0.7027429484610169). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfaec22d9e247468aaf2470d70140fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2748), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.456253868223417 - Jaccard: 0.7377256109157847\n",
      "Loss: 1.432737732231617 - Jaccard: 0.7508758968239602\n",
      "Loss: 1.419961133003235 - Jaccard: 0.7357621964040577\n",
      "Loss: 1.5161054664850235 - Jaccard: 0.7304498509939492\n",
      "Loss: 1.4336817690730095 - Jaccard: 0.7355223079893501\n",
      "Loss: 1.4963116344809533 - Jaccard: 0.7169645771876769\n",
      "Loss: 1.4195582857728004 - Jaccard: 0.727467005873169\n",
      "Loss: 1.484325020313263 - Jaccard: 0.7336636612125463\n",
      "Loss: 1.483836367726326 - Jaccard: 0.7130708372855363\n",
      "Loss: 1.499843258559704 - Jaccard: 0.7394320899672205\n",
      "Loss: 1.4730656361579895 - Jaccard: 0.7311902229330921\n",
      "Loss: 1.472093179821968 - Jaccard: 0.7337734901713495\n",
      "Loss: 1.5409895172715187 - Jaccard: 0.7206307811280938\n",
      "Loss: 1.529994381070137 - Jaccard: 0.7131734943643744\n",
      "Loss: 1.494701928794384 - Jaccard: 0.7177375697527616\n",
      "Loss: 1.4377261531352996 - Jaccard: 0.7395234486284699\n",
      "Loss: 1.4851282092928886 - Jaccard: 0.7424698644291986\n",
      "Loss: 1.5411504071950912 - Jaccard: 0.7132853859728909\n",
      "Loss: 1.4033497855067254 - Jaccard: 0.7385573857833474\n",
      "Loss: 1.5140867841243744 - Jaccard: 0.7316597892468133\n",
      "Loss: 1.4426004260778427 - Jaccard: 0.7336554944486238\n",
      "Loss: 1.5608162987232208 - Jaccard: 0.7090979405983573\n",
      "Loss: 1.3779650431871415 - Jaccard: 0.737154974453296\n",
      "Loss: 1.5072735232114791 - Jaccard: 0.7239033755329021\n",
      "Loss: 1.424424803853035 - Jaccard: 0.7427161400922259\n",
      "Loss: 1.4787749245762825 - Jaccard: 0.7304492247623151\n",
      "Loss: 1.4323306721448898 - Jaccard: 0.7513200204919144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e116b9028a459e99a1327e1d9a892d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=688), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.6957868377831454\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217b67ac15d04270a43f3c136de1d763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2748), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.083650127790942 - Jaccard: 0.7899867427707716\n",
      "Loss: 1.1184110862016678 - Jaccard: 0.7707891515089657\n",
      "Loss: 1.0239257436990739 - Jaccard: 0.8062241209104792\n",
      "Loss: 1.1211995008587836 - Jaccard: 0.7827344028009219\n",
      "Loss: 1.0303364756703377 - Jaccard: 0.7900712644978486\n",
      "Loss: 1.0412088388204574 - Jaccard: 0.7960908911242696\n",
      "Loss: 0.9626351654529571 - Jaccard: 0.7967571745616147\n",
      "Loss: 1.127851814031601 - Jaccard: 0.7671428821959511\n",
      "Loss: 1.044112186729908 - Jaccard: 0.7910692179409129\n",
      "Loss: 0.9897830283641815 - Jaccard: 0.7875691607250175\n",
      "Loss: 1.024745173752308 - Jaccard: 0.7909579386668074\n",
      "Loss: 1.0912082123756408 - Jaccard: 0.7649691001310447\n",
      "Loss: 1.1394722107052804 - Jaccard: 0.7725228403823852\n",
      "Loss: 0.9692498990893363 - Jaccard: 0.8032521642624475\n",
      "Loss: 1.0680256149172782 - Jaccard: 0.7921167889149424\n",
      "Loss: 1.040019938275218 - Jaccard: 0.8027529557697487\n",
      "Loss: 1.0718903666734696 - Jaccard: 0.7901800276092235\n",
      "Loss: 1.0320831800997257 - Jaccard: 0.7940996807036947\n",
      "Loss: 1.1239271235466004 - Jaccard: 0.7718016158091936\n",
      "Loss: 0.9825539839267731 - Jaccard: 0.8012693034449623\n",
      "Loss: 1.037804351747036 - Jaccard: 0.7927058157551778\n",
      "Loss: 1.0240822806954384 - Jaccard: 0.7972215015785337\n",
      "Loss: 1.0638972499966621 - Jaccard: 0.7932983778525923\n",
      "Loss: 1.0551937238872051 - Jaccard: 0.7893726479359995\n",
      "Loss: 1.0648715835809708 - Jaccard: 0.7933805861980169\n",
      "Loss: 1.0637705066800118 - Jaccard: 0.7850684651229837\n",
      "Loss: 1.0255904336273671 - Jaccard: 0.785988553501237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7983353655f4206bbdfd9ade75939fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=688), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0426 01:10:53.158895 139864187406080 modeling_utils.py:384] loading weights file /data/ai_challenge/tweet_sentiment_extraction/bert-base-uncased/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.700268322000635\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Early stopping\n",
      "Train Fold 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f6f022b4be489a8e4aeb00decf7ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2749), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 4.131379029538372 - Jaccard: 0.5456695245048565\n",
      "Loss: 2.4675424838066102 - Jaccard: 0.6202544722406413\n",
      "Loss: 2.312286288142204 - Jaccard: 0.6383981655289267\n",
      "Loss: 2.006708064675331 - Jaccard: 0.6774616979091952\n",
      "Loss: 2.078600796163082 - Jaccard: 0.6576797574881907\n",
      "Loss: 1.9669051307439804 - Jaccard: 0.6750861036273536\n",
      "Loss: 1.9062970158457757 - Jaccard: 0.6985514099174069\n",
      "Loss: 1.8667505809664726 - Jaccard: 0.692750042713667\n",
      "Loss: 2.019109428524971 - Jaccard: 0.6700419305920051\n",
      "Loss: 1.947121599316597 - Jaccard: 0.6705616237771386\n",
      "Loss: 1.8395690619945526 - Jaccard: 0.6922063263475488\n",
      "Loss: 1.9346526181697845 - Jaccard: 0.6741102043217099\n",
      "Loss: 1.962025713324547 - Jaccard: 0.6669156982919265\n",
      "Loss: 1.8171371841430664 - Jaccard: 0.6981547837065165\n",
      "Loss: 1.8451337176561355 - Jaccard: 0.701321805378443\n",
      "Loss: 1.880200001001358 - Jaccard: 0.6949488748077671\n",
      "Loss: 1.7475495153665543 - Jaccard: 0.7015526671745025\n",
      "Loss: 1.8271014299988746 - Jaccard: 0.6743317880718801\n",
      "Loss: 1.806049458384514 - Jaccard: 0.6792392234665268\n",
      "Loss: 1.7897267505526542 - Jaccard: 0.6978401016640886\n",
      "Loss: 1.7259289273619651 - Jaccard: 0.697228325618385\n",
      "Loss: 1.7653472530841827 - Jaccard: 0.6874541592824568\n",
      "Loss: 1.8996158999204635 - Jaccard: 0.6846654419890527\n",
      "Loss: 1.7582675176858902 - Jaccard: 0.6969909874847374\n",
      "Loss: 1.7723576799035072 - Jaccard: 0.6992991205915725\n",
      "Loss: 1.816363023519516 - Jaccard: 0.6887347871337637\n",
      "Loss: 1.7874401825666428 - Jaccard: 0.6761109885986045\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20170ad5ae5b4a04a94a6d6d2dfd13b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.696875335335317\n",
      "Validation score improved (-inf --> 0.696875335335317). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20213158a2a142b48ef6c0f8b8ad4b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2749), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4994063521965895 - Jaccard: 0.7325438990462689\n",
      "Loss: 1.4641456162929536 - Jaccard: 0.7419673041769091\n",
      "Loss: 1.5068176278471948 - Jaccard: 0.7266337621577823\n",
      "Loss: 1.4150820636749268 - Jaccard: 0.7367689223784956\n",
      "Loss: 1.417411946952343 - Jaccard: 0.7246451720049555\n",
      "Loss: 1.4442904382944106 - Jaccard: 0.7325651628957819\n",
      "Loss: 1.5625090879201888 - Jaccard: 0.7184263822794869\n",
      "Loss: 1.457356193959713 - Jaccard: 0.7300801814173191\n",
      "Loss: 1.5025572502613067 - Jaccard: 0.7292004372060643\n",
      "Loss: 1.3927627649903298 - Jaccard: 0.7419757418911925\n",
      "Loss: 1.6507721954584123 - Jaccard: 0.6900033234438421\n",
      "Loss: 1.4805974617600441 - Jaccard: 0.7394060518085284\n",
      "Loss: 1.4194888329505921 - Jaccard: 0.7340950518649659\n",
      "Loss: 1.5119445186853409 - Jaccard: 0.716236854547998\n",
      "Loss: 1.454479334950447 - Jaccard: 0.7285139313532203\n",
      "Loss: 1.6197334748506547 - Jaccard: 0.7131072124844118\n",
      "Loss: 1.5309252420067787 - Jaccard: 0.7433224679732032\n",
      "Loss: 1.4237790083885193 - Jaccard: 0.7345803307837859\n",
      "Loss: 1.6069936192035674 - Jaccard: 0.696686662691597\n",
      "Loss: 1.4423560667037965 - Jaccard: 0.7292542792275534\n",
      "Loss: 1.4897007250785828 - Jaccard: 0.7274864692801476\n",
      "Loss: 1.4541375929117202 - Jaccard: 0.7441307767734987\n",
      "Loss: 1.486320121884346 - Jaccard: 0.7397342497461242\n",
      "Loss: 1.4847595062851906 - Jaccard: 0.7250186555393858\n",
      "Loss: 1.4240227207541465 - Jaccard: 0.7352920419171548\n",
      "Loss: 1.5670759838819504 - Jaccard: 0.6999125259001349\n",
      "Loss: 1.3656610342860223 - Jaccard: 0.7459402979551929\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43132c3292c5412ca3cd7fdfda699abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.7011417559041289\n",
      "Validation score improved (0.696875335335317 --> 0.7011417559041289). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffbd83e33d04f43955c5ff2a2376592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2749), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1004580417186907 - Jaccard: 0.7860456769342651\n",
      "Loss: 1.011516844779253 - Jaccard: 0.7974109035809467\n",
      "Loss: 1.0579987615346909 - Jaccard: 0.7931042220675019\n",
      "Loss: 1.0547941291332246 - Jaccard: 0.7914018551810115\n",
      "Loss: 1.076277250945568 - Jaccard: 0.7854519856998529\n",
      "Loss: 0.9699429592490196 - Jaccard: 0.807469717245259\n",
      "Loss: 1.084708569943905 - Jaccard: 0.7745589409011531\n",
      "Loss: 1.0417032894492149 - Jaccard: 0.8049156313374205\n",
      "Loss: 1.0366667664051057 - Jaccard: 0.7753715248005051\n",
      "Loss: 1.000251711010933 - Jaccard: 0.8052805213117357\n",
      "Loss: 1.0138977479934692 - Jaccard: 0.803007423523703\n",
      "Loss: 1.0481782159209252 - Jaccard: 0.7661813793302951\n",
      "Loss: 1.0631202456355096 - Jaccard: 0.7895974388338535\n",
      "Loss: 1.1184745854139329 - Jaccard: 0.7809326985429043\n",
      "Loss: 0.9854915469884873 - Jaccard: 0.799181016816608\n",
      "Loss: 1.1482181166112424 - Jaccard: 0.7758473235094497\n",
      "Loss: 1.180724088549614 - Jaccard: 0.7837947407822616\n",
      "Loss: 1.0938086956739426 - Jaccard: 0.786445047368567\n",
      "Loss: 1.0343587830662728 - Jaccard: 0.7906644497918812\n",
      "Loss: 1.0446759882569312 - Jaccard: 0.7945201629237688\n",
      "Loss: 1.0499807167053223 - Jaccard: 0.8008104264765294\n",
      "Loss: 1.0234778827428819 - Jaccard: 0.7915269916000957\n",
      "Loss: 1.0441222274303437 - Jaccard: 0.7977061274673228\n",
      "Loss: 1.0631507509946823 - Jaccard: 0.7935056813180629\n",
      "Loss: 1.089813841879368 - Jaccard: 0.79614811739828\n",
      "Loss: 1.065105857849121 - Jaccard: 0.8010216980850285\n",
      "Loss: 1.0770077422261237 - Jaccard: 0.7820630274749756\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bb82e6353747708e84900efe3f9f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.6929554526187361\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583fb2ffea8b427ca9cbc721e39e219b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2749), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6173136530831309 - Jaccard: 0.8617079775731431\n",
      "Loss: 0.6375527827441693 - Jaccard: 0.8453013536450651\n",
      "Loss: 0.7026452292501927 - Jaccard: 0.8541909161775041\n",
      "Loss: 0.6831801827251911 - Jaccard: 0.8433272542235813\n",
      "Loss: 0.5769408913701772 - Jaccard: 0.8644301690274403\n",
      "Loss: 0.6985217029601336 - Jaccard: 0.8389033431105859\n",
      "Loss: 0.668329411149025 - Jaccard: 0.8489918694651977\n",
      "Loss: 0.7128353004157543 - Jaccard: 0.8373615921591397\n",
      "Loss: 0.6797185006737709 - Jaccard: 0.8390173016426032\n",
      "Loss: 0.7085574121773243 - Jaccard: 0.8540307420676139\n",
      "Loss: 0.6403227354586124 - Jaccard: 0.8676752415906249\n",
      "Loss: 0.6542784689366817 - Jaccard: 0.8471978186128643\n",
      "Loss: 0.6659809416532516 - Jaccard: 0.8442402022701905\n",
      "Loss: 0.6711973598599434 - Jaccard: 0.8665008465756884\n",
      "Loss: 0.6137027791142464 - Jaccard: 0.8557391617807063\n",
      "Loss: 0.7011162474751472 - Jaccard: 0.8463590497631569\n",
      "Loss: 0.7150163793563843 - Jaccard: 0.8531044562527179\n",
      "Loss: 0.6307059679925442 - Jaccard: 0.8555657184063077\n",
      "Loss: 0.6654250641912222 - Jaccard: 0.8469176605081923\n",
      "Loss: 0.660527758449316 - Jaccard: 0.8495721712838877\n",
      "Loss: 0.6274292772263288 - Jaccard: 0.8521855338645422\n",
      "Loss: 0.6053427389264107 - Jaccard: 0.858838842753394\n",
      "Loss: 0.6694454948604107 - Jaccard: 0.8461571792186346\n",
      "Loss: 0.7229297970980406 - Jaccard: 0.837472684680693\n",
      "Loss: 0.6479803992062807 - Jaccard: 0.8446471974759417\n",
      "Loss: 0.695872095823288 - Jaccard: 0.8486458833217645\n",
      "Loss: 0.5777873980253935 - Jaccard: 0.872084513253335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1af9233f4a42dd950668f92400325b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0426 02:13:30.891991 139864187406080 modeling_utils.py:384] loading weights file /data/ai_challenge/tweet_sentiment_extraction/bert-base-uncased/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.686046587489046\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Early stopping\n",
      "Train Fold 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd8402a318a45bd9184680f3dc2d7ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2749), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.957115610047142 - Jaccard: 0.5743215172253557\n",
      "Loss: 2.503328174948692 - Jaccard: 0.6094575514182323\n",
      "Loss: 2.291693057715893 - Jaccard: 0.6489431036157443\n",
      "Loss: 2.1018513053655625 - Jaccard: 0.6592310634003005\n",
      "Loss: 2.0894598829746247 - Jaccard: 0.6763796894365767\n",
      "Loss: 2.1152956050634386 - Jaccard: 0.640902073416686\n",
      "Loss: 1.9093018049001693 - Jaccard: 0.6868650719110502\n",
      "Loss: 1.893374165892601 - Jaccard: 0.668292534403432\n",
      "Loss: 2.083606230020523 - Jaccard: 0.6609861109953147\n",
      "Loss: 1.923269934654236 - Jaccard: 0.6849875391116075\n",
      "Loss: 2.0732654185593127 - Jaccard: 0.6589866293851668\n",
      "Loss: 1.7381196624040605 - Jaccard: 0.6960415772960011\n",
      "Loss: 1.9154135650396347 - Jaccard: 0.6857828325532845\n",
      "Loss: 1.8193187233805657 - Jaccard: 0.6816999635476608\n",
      "Loss: 1.858154098391533 - Jaccard: 0.6898709910837337\n",
      "Loss: 1.8192259129881858 - Jaccard: 0.6891580922590296\n",
      "Loss: 1.905450363755226 - Jaccard: 0.6758405701497111\n",
      "Loss: 1.7131214880943297 - Jaccard: 0.6897529714271852\n",
      "Loss: 1.7282006376981736 - Jaccard: 0.6974239661732109\n",
      "Loss: 1.6930826890468598 - Jaccard: 0.7023910130198804\n",
      "Loss: 1.8201662993431091 - Jaccard: 0.6871194087294041\n",
      "Loss: 1.8623345211148261 - Jaccard: 0.6823294722351315\n",
      "Loss: 1.8600954025983811 - Jaccard: 0.6877177909091209\n",
      "Loss: 1.7784800788760184 - Jaccard: 0.6928303296767172\n",
      "Loss: 1.799641637802124 - Jaccard: 0.6988663050121302\n",
      "Loss: 1.891750938296318 - Jaccard: 0.6669149749247366\n",
      "Loss: 1.7708191341161728 - Jaccard: 0.6997449112811835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0fe44c96f647b998e458b727224046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.7084764475712458\n",
      "Validation score improved (-inf --> 0.7084764475712458). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793b1604f49748dda2f71b8131e99d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2749), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6094354818953145 - Jaccard: 0.7274121120923334\n",
      "Loss: 1.6032496851682663 - Jaccard: 0.7052773276182304\n",
      "Loss: 1.4050411561131477 - Jaccard: 0.734766570323755\n",
      "Loss: 1.4251287716627121 - Jaccard: 0.7295468238091547\n",
      "Loss: 1.4383855217695236 - Jaccard: 0.7437501096827107\n",
      "Loss: 1.4706201681494713 - Jaccard: 0.7320091160617328\n",
      "Loss: 1.4365833279490472 - Jaccard: 0.7334819612400938\n",
      "Loss: 1.4868589219450952 - Jaccard: 0.7353368056478192\n",
      "Loss: 1.5378033024072648 - Jaccard: 0.7299970155210284\n",
      "Loss: 1.5529287469387054 - Jaccard: 0.6994966001217623\n",
      "Loss: 1.544970475435257 - Jaccard: 0.7255443568348636\n",
      "Loss: 1.6520982247591018 - Jaccard: 0.7138669540051487\n",
      "Loss: 1.5203256672620773 - Jaccard: 0.733757909067944\n",
      "Loss: 1.6108260598778725 - Jaccard: 0.7114563781744326\n",
      "Loss: 1.4418796774744989 - Jaccard: 0.7162282096378648\n",
      "Loss: 1.5036164888739585 - Jaccard: 0.7120927793541115\n",
      "Loss: 1.5117526349425316 - Jaccard: 0.727427734836113\n",
      "Loss: 1.537513672709465 - Jaccard: 0.72412111351635\n",
      "Loss: 1.560505313873291 - Jaccard: 0.7025114092386354\n",
      "Loss: 1.4511941039562226 - Jaccard: 0.7254274385752911\n",
      "Loss: 1.5106404423713684 - Jaccard: 0.7332747998307458\n",
      "Loss: 1.5036811169981956 - Jaccard: 0.7240362692767751\n",
      "Loss: 1.505085835158825 - Jaccard: 0.7189236650292572\n",
      "Loss: 1.5107740396261216 - Jaccard: 0.739805542706133\n",
      "Loss: 1.4141028425097466 - Jaccard: 0.749621847860331\n",
      "Loss: 1.3608084493875503 - Jaccard: 0.7360936769360242\n",
      "Loss: 1.4508077159523964 - Jaccard: 0.7483684746481645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afdf8e3aa1346c7bac07805fc95baeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.7141036364033579\n",
      "Validation score improved (0.7084764475712458 --> 0.7141036364033579). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd81f88358b40ad8c6e416651df08a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2749), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0203930924434472 - Jaccard: 0.7917715209510015\n",
      "Loss: 1.1206414696574212 - Jaccard: 0.7767008640990645\n",
      "Loss: 1.1288139626383782 - Jaccard: 0.7741833277544257\n",
      "Loss: 1.129126259982586 - Jaccard: 0.7780497246045541\n",
      "Loss: 1.0494600482285024 - Jaccard: 0.7790325219059838\n",
      "Loss: 1.0748820962011814 - Jaccard: 0.7995052742651433\n",
      "Loss: 1.109474211037159 - Jaccard: 0.7902961895929917\n",
      "Loss: 1.1659309920668601 - Jaccard: 0.7732570242163423\n",
      "Loss: 1.1301618553698063 - Jaccard: 0.7850112259788655\n",
      "Loss: 1.1143588626384735 - Jaccard: 0.7702336494977686\n",
      "Loss: 1.1575595581531524 - Jaccard: 0.7787054319543766\n",
      "Loss: 1.1071906965970992 - Jaccard: 0.7750260586109369\n",
      "Loss: 1.0518892189860345 - Jaccard: 0.791218295677108\n",
      "Loss: 1.068937139213085 - Jaccard: 0.7894719815712756\n",
      "Loss: 1.1188599161803723 - Jaccard: 0.7867410019391065\n",
      "Loss: 1.0741998073458672 - Jaccard: 0.7828952828121813\n",
      "Loss: 1.0513454385101795 - Jaccard: 0.7870636356665243\n",
      "Loss: 1.1402086895704269 - Jaccard: 0.7694540690101671\n",
      "Loss: 1.0611586053669453 - Jaccard: 0.7895883664040028\n",
      "Loss: 1.1050024615228176 - Jaccard: 0.7852381932035561\n",
      "Loss: 1.0272957423329354 - Jaccard: 0.7897918378642882\n",
      "Loss: 1.014687149375677 - Jaccard: 0.8134633736834671\n",
      "Loss: 1.0235367983579635 - Jaccard: 0.7988611440928913\n",
      "Loss: 1.0960102041065694 - Jaccard: 0.7762030513453695\n",
      "Loss: 0.9962727622687817 - Jaccard: 0.798106834702638\n",
      "Loss: 1.0845679092407225 - Jaccard: 0.7836074480082273\n",
      "Loss: 1.121587951183319 - Jaccard: 0.783251301882849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699187e3f8724a4cbf8ca06b03a69599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.6963811122408767\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6a25db7de4401ea48b34c8fb8cdae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2749), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6915544146063304 - Jaccard: 0.8452065194260058\n",
      "Loss: 0.6318357204645872 - Jaccard: 0.8495486543979557\n",
      "Loss: 0.6962790650129318 - Jaccard: 0.8479150900116171\n",
      "Loss: 0.7342992876470089 - Jaccard: 0.8351676872710722\n",
      "Loss: 0.7190980030596257 - Jaccard: 0.8508523255564486\n",
      "Loss: 0.6296802043914795 - Jaccard: 0.8552999328147419\n",
      "Loss: 0.6700930424034596 - Jaccard: 0.8538562687321091\n",
      "Loss: 0.6836408899724483 - Jaccard: 0.858186597170413\n",
      "Loss: 0.6845359553396702 - Jaccard: 0.835900368649818\n",
      "Loss: 0.6361523762345314 - Jaccard: 0.8644377763007589\n",
      "Loss: 0.7083011068403721 - Jaccard: 0.8425824673601273\n",
      "Loss: 0.7246220940351487 - Jaccard: 0.8438182384857725\n",
      "Loss: 0.715951601266861 - Jaccard: 0.8393948745545596\n",
      "Loss: 0.7301467809081078 - Jaccard: 0.8289989447196082\n",
      "Loss: 0.6646251973882318 - Jaccard: 0.8498355306555837\n",
      "Loss: 0.7230915129184723 - Jaccard: 0.8383146412744961\n",
      "Loss: 0.6578884265571833 - Jaccard: 0.8438575715996002\n",
      "Loss: 0.6284659255295992 - Jaccard: 0.8624067610655168\n",
      "Loss: 0.752905045747757 - Jaccard: 0.8252786446375727\n",
      "Loss: 0.7176775980740786 - Jaccard: 0.8361139159763097\n",
      "Loss: 0.6826882012188434 - Jaccard: 0.8471270845261756\n",
      "Loss: 0.6809313923120499 - Jaccard: 0.855145505655335\n",
      "Loss: 0.6235651633888483 - Jaccard: 0.8645903255966154\n",
      "Loss: 0.7257590261101723 - Jaccard: 0.8526447887076039\n",
      "Loss: 0.6936166842281818 - Jaccard: 0.8388341854101412\n",
      "Loss: 0.7011761043965816 - Jaccard: 0.853403423661074\n",
      "Loss: 0.6780785807967186 - Jaccard: 0.8514561182130955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af171198b9e24338809420af4f84f514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0426 03:16:08.853911 139864187406080 modeling_utils.py:384] loading weights file /data/ai_challenge/tweet_sentiment_extraction/bert-base-uncased/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.6957977689536566\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Early stopping\n",
      "Train Fold 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ae9f2aeb6343be907cae01c0a7891a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2749), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.866982638245762 - Jaccard: 0.5832969384941282\n",
      "Loss: 2.512176737189293 - Jaccard: 0.6044478649997962\n",
      "Loss: 2.2072829037904738 - Jaccard: 0.6478503691584966\n",
      "Loss: 2.0806332713365556 - Jaccard: 0.659156920909496\n",
      "Loss: 2.171147363781929 - Jaccard: 0.6439349483115171\n",
      "Loss: 2.0125829535722732 - Jaccard: 0.6729104815028158\n",
      "Loss: 1.9713353776931763 - Jaccard: 0.6772864351082802\n",
      "Loss: 1.9924335139989853 - Jaccard: 0.6563896212385741\n",
      "Loss: 1.9599557876586915 - Jaccard: 0.6621429308729422\n",
      "Loss: 1.8652702990174292 - Jaccard: 0.6969418129777913\n",
      "Loss: 1.7828771328926087 - Jaccard: 0.6925310130545818\n",
      "Loss: 1.8293436223268509 - Jaccard: 0.6744049708033067\n",
      "Loss: 1.993977781534195 - Jaccard: 0.6582195708621192\n",
      "Loss: 1.9055063605308533 - Jaccard: 0.662875180303368\n",
      "Loss: 1.865543693304062 - Jaccard: 0.6729118560237473\n",
      "Loss: 1.87390487074852 - Jaccard: 0.685677717123152\n",
      "Loss: 1.893412288427353 - Jaccard: 0.6841445965382883\n",
      "Loss: 1.8366708087921142 - Jaccard: 0.6711764202158088\n",
      "Loss: 1.827158977985382 - Jaccard: 0.6990628946358509\n",
      "Loss: 1.8555260056257248 - Jaccard: 0.6855401334425211\n",
      "Loss: 1.851314784884453 - Jaccard: 0.7041366003069521\n",
      "Loss: 1.8616936272382736 - Jaccard: 0.6760255174729757\n",
      "Loss: 1.7351544293761254 - Jaccard: 0.7066552830361071\n",
      "Loss: 1.692786042690277 - Jaccard: 0.7140381193264848\n",
      "Loss: 1.7388090980052948 - Jaccard: 0.6941461917319549\n",
      "Loss: 1.728353733420372 - Jaccard: 0.7002334556115393\n",
      "Loss: 1.8621458289027215 - Jaccard: 0.6810282953093519\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d675613cff1846578a357a8c93897442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.6972649499515994\n",
      "Validation score improved (-inf --> 0.6972649499515994). Saving model!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232c796c59f541a2bc2280defbe795be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2749), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4557868652414567 - Jaccard: 0.7489423385609864\n",
      "Loss: 1.511812302172184 - Jaccard: 0.7227037581151647\n",
      "Loss: 1.2974335381388664 - Jaccard: 0.7570847673353479\n",
      "Loss: 1.5244905769824981 - Jaccard: 0.7371176018051548\n",
      "Loss: 1.5194003239274025 - Jaccard: 0.7334389141695135\n",
      "Loss: 1.49105104804039 - Jaccard: 0.7192172699700697\n",
      "Loss: 1.5214613628387452 - Jaccard: 0.7137459086039292\n",
      "Loss: 1.4389581969380378 - Jaccard: 0.729086784588671\n",
      "Loss: 1.5028460919857025 - Jaccard: 0.733141986306906\n",
      "Loss: 1.5228749388456344 - Jaccard: 0.7265329354076848\n",
      "Loss: 1.4801782149076461 - Jaccard: 0.7439439599057631\n",
      "Loss: 1.4979138001799583 - Jaccard: 0.7310023423958952\n",
      "Loss: 1.6523909589648247 - Jaccard: 0.7188076184620619\n",
      "Loss: 1.5042451202869416 - Jaccard: 0.7245283624362451\n",
      "Loss: 1.482791654765606 - Jaccard: 0.7428477544869171\n",
      "Loss: 1.4092244058847427 - Jaccard: 0.7511603639728041\n",
      "Loss: 1.3878144717216492 - Jaccard: 0.7401971154602565\n",
      "Loss: 1.4409482270479201 - Jaccard: 0.7402760711775456\n",
      "Loss: 1.5218962121009827 - Jaccard: 0.7311557522406941\n",
      "Loss: 1.5352915155887603 - Jaccard: 0.7312321466725382\n",
      "Loss: 1.4469506487250328 - Jaccard: 0.733884436521869\n",
      "Loss: 1.4366618061065675 - Jaccard: 0.7381675549553646\n",
      "Loss: 1.4689174392819404 - Jaccard: 0.718887258985649\n",
      "Loss: 1.406776959002018 - Jaccard: 0.7362268231913909\n",
      "Loss: 1.5770406475663186 - Jaccard: 0.71837316257637\n",
      "Loss: 1.569378107190132 - Jaccard: 0.7095564554404139\n",
      "Loss: 1.4671242779493332 - Jaccard: 0.7265474447201815\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e695de43d54357be66d216d206a6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.6946055779990511\n",
      "EarlyStopping counter: 1 out of 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a114550849d44d54a14143d29c739480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2749), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0429256942012521 - Jaccard: 0.7934992678614856\n",
      "Loss: 1.062065132856369 - Jaccard: 0.8007779229648839\n",
      "Loss: 1.0403044363856315 - Jaccard: 0.7876143928350798\n",
      "Loss: 0.987800139784813 - Jaccard: 0.7998503529670739\n",
      "Loss: 1.1669888666272163 - Jaccard: 0.7700310562935353\n",
      "Loss: 1.0783107428252696 - Jaccard: 0.7854987109534993\n",
      "Loss: 1.0647250846028329 - Jaccard: 0.800814799658415\n",
      "Loss: 1.0023440396785737 - Jaccard: 0.7885185737218147\n",
      "Loss: 1.0596109688282014 - Jaccard: 0.8044258572653699\n",
      "Loss: 1.0654757928848266 - Jaccard: 0.7946464921392191\n",
      "Loss: 1.0451233641803264 - Jaccard: 0.8004563033059955\n",
      "Loss: 1.076701924800873 - Jaccard: 0.784338012910927\n",
      "Loss: 0.8958338136970997 - Jaccard: 0.8008538094118139\n",
      "Loss: 1.0498445466160775 - Jaccard: 0.7985606045217132\n",
      "Loss: 1.106883365213871 - Jaccard: 0.7906696442602396\n",
      "Loss: 1.0904978999495507 - Jaccard: 0.7819779729714789\n",
      "Loss: 1.0959253200888635 - Jaccard: 0.781870105732107\n",
      "Loss: 1.0570912951231002 - Jaccard: 0.7832638525208289\n",
      "Loss: 1.1441837325692177 - Jaccard: 0.7717704798147799\n",
      "Loss: 1.0863777446746825 - Jaccard: 0.7986302999177327\n",
      "Loss: 1.0379085013270377 - Jaccard: 0.8073564744238204\n",
      "Loss: 1.0059163059294223 - Jaccard: 0.8037486412452046\n",
      "Loss: 1.0664494973421097 - Jaccard: 0.7788352640388058\n",
      "Loss: 1.03234587341547 - Jaccard: 0.7873931575623547\n",
      "Loss: 0.9941067758202553 - Jaccard: 0.8140639742514147\n",
      "Loss: 1.0212995877861977 - Jaccard: 0.8049858838384678\n",
      "Loss: 1.0717760238051415 - Jaccard: 0.7807361847083104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f9c160e77e49ee9ed215d58679e3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval Jaccard = 0.6907326772750885\n",
      "EarlyStopping counter: 2 out of 2\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(config.DATA_DIR, config.TRAIN_FILE))\n",
    "train_df = train_df.dropna(how='any', axis=0)\n",
    "splits = list(StratifiedKFold(n_splits=config.N_SPLITS, shuffle=True, random_state=config.SEED).split(train_df, train_df['sentiment']))\n",
    "\n",
    "model_config = transformers.BertConfig.from_pretrained(config.BERT_PATH)\n",
    "model_config.output_hidden_states = True\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(splits):\n",
    "    print('---Train Fold {}---'.format(fold))\n",
    "    \n",
    "    fold_train_df = train_df.iloc[train_idx, :]\n",
    "    fold_valid_df = train_df.iloc[val_idx, :]\n",
    "    \n",
    "    train_dataset = TweetDataset(\n",
    "        tweet = fold_train_df.text.values,\n",
    "        sentiment = fold_train_df.sentiment.values,\n",
    "        selected_text = fold_train_df.selected_text.values\n",
    "    )\n",
    "    \n",
    "    valid_dataset = TweetDataset(\n",
    "        tweet = fold_valid_df.text.values,\n",
    "        sentiment = fold_valid_df.sentiment.values,\n",
    "        selected_text = fold_valid_df.selected_text.values\n",
    "    )\n",
    "    \n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size = config.TRAIN_BATCH_SIZE,\n",
    "        shuffle = True,\n",
    "        num_workers = 8\n",
    "    )\n",
    "    \n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size = config.VALID_BATCH_SIZE,\n",
    "        shuffle = False,\n",
    "        num_workers = 8\n",
    "    )\n",
    "    \n",
    "    run(fold=fold, \n",
    "        train_data_loader=train_data_loader, \n",
    "        valid_data_loader=valid_data_loader, \n",
    "        train_size=len(train_idx),\n",
    "        model_config=model_config\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(config.DATA_DIR, config.TEST_FILE))\n",
    "test_df.loc[:, 'selected_text'] = test_df.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0424 22:58:20.596534 139864187406080 configuration_utils.py:149] loading configuration file /data/ai_challenge/tweet_sentiment_extraction/bert-base-uncased/config.json\n",
      "I0424 22:58:20.600911 139864187406080 configuration_utils.py:169] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = transformers.BertConfig.from_pretrained(config.BERT_PATH)\n",
    "model_config.output_hidden_states = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = TweetModel(conf=model_config)\n",
    "model1.to(config.DEVICE)\n",
    "model1.load_state_dict(torch.load(f\"{config.OUTPUT_DIR}/{config.SAVE_MODEL_DIR}/model_fold_0.bin\"))\n",
    "model1.eval()\n",
    "\n",
    "model2 = TweetModel(conf=model_config)\n",
    "model2.to(config.DEVICE)\n",
    "model2.load_state_dict(torch.load(f\"{config.OUTPUT_DIR}/{config.SAVE_MODEL_DIR}/model_fold_1.bin\"))\n",
    "model2.eval()\n",
    "\n",
    "model3 = TweetModel(conf=model_config)\n",
    "model3.to(config.DEVICE)\n",
    "model3.load_state_dict(torch.load(f\"{config.OUTPUT_DIR}/{config.SAVE_MODEL_DIR}/model_fold_2.bin\"))\n",
    "model3.eval()\n",
    "\n",
    "model4 = TweetModel(conf=model_config)\n",
    "model4.to(config.DEVICE)\n",
    "model4.load_state_dict(torch.load(f\"{config.OUTPUT_DIR}/{config.SAVE_MODEL_DIR}/model_fold_3.bin\"))\n",
    "model4.eval()\n",
    "\n",
    "model5 = TweetModel(conf=model_config)\n",
    "model5.to(config.DEVICE)\n",
    "model5.load_state_dict(torch.load(f\"{config.OUTPUT_DIR}/{config.SAVE_MODEL_DIR}/model_fold_4.bin\"))\n",
    "model5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0424 23:18:49.669809 139864187406080 modeling_utils.py:384] loading weights file /data/ai_challenge/tweet_sentiment_extraction/bert-base-uncased/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f975cb90ff8461d98642934a19f37ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=442), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-17-b83926e6aba2>\u001b[0m(26)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     24 \u001b[0;31m    \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m        \u001b[0mtk0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 26 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mbi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtk0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m            \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m            \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> outputs_start.shape\n",
      "(8, 128)\n",
      "ipdb> np.argmax(outputs_start)\n",
      "387\n",
      "ipdb> np.argmax(outputs_start[0, :])\n",
      "3\n",
      "ipdb> q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b83926e6aba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtk0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtk0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-b83926e6aba2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtk0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtk0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/kits/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/kits/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "final_output = []\n",
    "\n",
    "test_dataset = TweetDataset(\n",
    "        tweet = test_df.text.values,\n",
    "        sentiment = test_df.sentiment.values,\n",
    "        selected_text = test_df.selected_text.values\n",
    ")\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = config.VALID_BATCH_SIZE,\n",
    "    shuffle = False,\n",
    "    num_workers = 8\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    tk0 = tqdm(test_data_loader, total=len(test_data_loader))\n",
    "    for bi, d in enumerate(tk0):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        sentiment = d[\"sentiment\"]\n",
    "        orig_selected = d[\"orig_selected\"]\n",
    "        orig_tweet = d[\"orig_tweet\"]\n",
    "        targets_start = d[\"targets_start\"]\n",
    "        targets_end = d[\"targets_end\"]\n",
    "        offsets = d[\"offsets\"].numpy()\n",
    "\n",
    "        ids = ids.to(config.DEVICE, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(config.DEVICE, dtype=torch.long)\n",
    "        mask = mask.to(config.DEVICE, dtype=torch.long)\n",
    "        targets_start = targets_start.to(config.DEVICE, dtype=torch.long)\n",
    "        targets_end = targets_end.to(config.DEVICE, dtype=torch.long)\n",
    "\n",
    "        outputs_start1, outputs_end1 = model1(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        outputs_start2, outputs_end2 = model2(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        outputs_start3, outputs_end3 = model3(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        outputs_start4, outputs_end4 = model4(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        outputs_start5, outputs_end5 = model5(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        outputs_start = (\n",
    "            outputs_start1 \n",
    "            + outputs_start2 \n",
    "            + outputs_start3 \n",
    "            + outputs_start4 \n",
    "            + outputs_start5\n",
    "        ) / 5\n",
    "        \n",
    "        outputs_end = (\n",
    "            outputs_end1 \n",
    "            + outputs_end2 \n",
    "            + outputs_end3 \n",
    "            + outputs_end4 \n",
    "            + outputs_end5\n",
    "        ) / 5\n",
    "        \n",
    "        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n",
    "        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n",
    "\n",
    "        for px, tweet in enumerate(orig_tweet):\n",
    "            selected_tweet = orig_selected[px]\n",
    "            tweet_sentiment = sentiment[px]\n",
    "            \n",
    "            _, output_sentence = calculate_jaccard_score(\n",
    "                original_tweet=tweet,\n",
    "                target_string=selected_tweet,\n",
    "                sentiment_val=tweet_sentiment,\n",
    "                idx_start=np.argmax(outputs_start[px, :]),\n",
    "                idx_end=np.argmax(outputs_end[px, :]),\n",
    "                offsets=offsets[px]\n",
    "            )\n",
    "            \n",
    "            final_output.append(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>http://twitpic.com/67ezh last session day the of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>shame! a such</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>it!! like i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                     selected_text\n",
       "0  f87dea47db  http://twitpic.com/67ezh last session day the of\n",
       "1  96d74cb729                                              good\n",
       "2  eee518ae67                                     shame! a such\n",
       "3  01082688c6                                       happy bday!\n",
       "4  33987a8ee5                                       it!! like i"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(os.path.join(config.DATA_DIR, \"sample_submission.csv\"))\n",
    "sample.loc[:, 'selected_text'] = final_output\n",
    "sample.to_csv(os.path.join(config.OUTPUT_DIR, \"submission.csv\"), index=False)\n",
    "\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
